{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377f4934",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math \n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "class SimpleTest():   \n",
    "    def __init__(self, r=1.0):\n",
    "        self.r = r\n",
    "        \n",
    "    class Simple(nn.Module):\n",
    "        def __init__(self, x):\n",
    "            super(SimpleTest.Simple, self).__init__()\n",
    "            self.x = torch.nn.Parameter(torch.tensor([x[0], x[1]]))\n",
    "    \n",
    "    def create_model(self, x):\n",
    "        return self.Simple(x)\n",
    "    \n",
    "    def f(self, model, X=None):\n",
    "        return model.x[0] + model.x[1]\n",
    "\n",
    "    def g(self, model, X=None):\n",
    "        return 0.5 * (model.x[0]**2 + (model.x[0] + model.x[1])**2 - self.r).reshape((1))\n",
    "    \n",
    "     \n",
    "class PoissonEqnByPINN():\n",
    "        \n",
    "    def __init__(self, u_coeff=1.0, size=2000, size_each_bndry=1000):    \n",
    "        # This parameter affects the magnitude of the gradients of the solution.\n",
    "        # Increasing its value makes the training more difficult.\n",
    "        self.X = self.sample_data_domain(size)\n",
    "        self.Y = self.sample_data_boundary(size_each_bndry)\n",
    "        self.ref_u = self.ref_u_nn(u_coeff)\n",
    "\n",
    "    # Reference solution\n",
    "    class ref_u_nn(nn.Module):\n",
    "        def __init__(self, coeff):\n",
    "            super(PoissonEqnByPINN.ref_u_nn, self).__init__()\n",
    "            self.coeff = coeff\n",
    "        def forward(self, x):\n",
    "            return (x[:,0]**2 + 1.0 * torch.sin(x[:,1] * self.coeff)).reshape((-1,1))      \n",
    "\n",
    "    def laplacian(self, model, x):\n",
    "        u = model(x)\n",
    "        u_x = torch.autograd.grad(\n",
    "                u.sum(), x,\n",
    "                retain_graph=True,\n",
    "                create_graph=True,\n",
    "                allow_unused=True\n",
    "            )[0]\n",
    "        u_xx = 0 \n",
    "        for i in range(2):\n",
    "            tmp = torch.autograd.grad(\n",
    "                     u_x[:,i].sum(), x,\n",
    "                     retain_graph=True,\n",
    "                     create_graph=True,\n",
    "                     allow_unused=True\n",
    "                 )[0]\n",
    "            if tmp is not None:\n",
    "                u_xx += tmp[:,i:i+1]\n",
    "        return u_xx\n",
    "    \n",
    "    def get_X(self):\n",
    "        return self.X\n",
    "    \n",
    "    def get_Y(self):\n",
    "        return self.Y\n",
    "    \n",
    "    def f(self, x):   \n",
    "        return self.laplacian(self.ref_u, x).detach()    \n",
    "\n",
    "    def g(self, x):\n",
    "        return self.ref_u(x).detach()\n",
    "\n",
    "    def F(self, model, x):\n",
    "        u_xx = self.laplacian(model, x)\n",
    "        return ((u_xx - self.f(x))**2).mean().reshape((1))\n",
    "\n",
    "    def G(self, model, x):\n",
    "        u = model(x)\n",
    "        return ((u-self.g(x))**2).mean().reshape((1))\n",
    "    \n",
    "    def sample_data_domain(self, size):\n",
    "        return np.random.rand(size, 2) \n",
    "\n",
    "    def sample_data_boundary(self, size_each_bndry):\n",
    "        # left boundary\n",
    "        data_whole = np.column_stack([np.zeros(size_each_bndry), np.random.rand(size_each_bndry)]) \n",
    "        # right boundary\n",
    "        data = np.column_stack([np.ones(size_each_bndry), np.random.rand(size_each_bndry)]) \n",
    "        data_whole = np.concatenate([data_whole, data])\n",
    "        # top boundary\n",
    "        data = np.column_stack([np.random.rand(size_each_bndry),np.ones(size_each_bndry)]) \n",
    "        data_whole = np.concatenate([data_whole, data])   \n",
    "        # bottom boundary\n",
    "        data = np.column_stack([np.random.rand(size_each_bndry),np.zeros(size_each_bndry)])     \n",
    "        data_whole = np.concatenate([data_whole, data])\n",
    "\n",
    "        return data_whole    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f5130",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
