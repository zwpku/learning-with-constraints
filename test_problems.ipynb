{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ec0269",
   "metadata": {},
   "source": [
    "## This notebook defines constrained problems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a0c33",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math \n",
    "import torch.nn as nn\n",
    "import random\n",
    "import itertools \n",
    "\n",
    "def create_sequential_nn(layer_dims, activation=torch.nn.Tanh()):\n",
    "    layers = torch.nn.Sequential()\n",
    "    for i in range(len(layer_dims)-2) :\n",
    "        layers.add_module(f'{i+1}',torch.nn.Linear(layer_dims[i], layer_dims[i+1])) \n",
    "        layers.add_module(f'acti {i+1}', activation)\n",
    "    layers.add_module('last', torch.nn.Linear(layer_dims[-2], layer_dims[-1])) \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f7a7b",
   "metadata": {},
   "source": [
    "## The first problem is very simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff18e3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "class SimpleTest():   \n",
    "    def __init__(self, r=1.0):\n",
    "        self.r = r\n",
    "        \n",
    "    class Simple(nn.Module):\n",
    "        def __init__(self, x):\n",
    "            super(SimpleTest.Simple, self).__init__()\n",
    "            self.x = torch.nn.Parameter(torch.tensor([x[0], x[1]]))\n",
    "    \n",
    "    def create_model(self, x):\n",
    "        return self.Simple(x)\n",
    "    \n",
    "    def F(self, model, X=None):\n",
    "        return model.x[0] + model.x[1]\n",
    "\n",
    "    def G(self, model, X=None):\n",
    "        return 0.5 * (model.x[0]**2 + (model.x[0] + model.x[1])**2 - self.r).reshape((1))\n",
    "#        return 0.5 * (model.x[0]**2 - self.r).reshape((1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27cd663",
   "metadata": {},
   "source": [
    "### The second one is a Possion equation on $[0,1]^2$ with PINN loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9660c0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "class PoissonEqnByPINN():\n",
    "        \n",
    "    def __init__(self, u_coeff=1.0, size=2000, size_each_bndry=1000):    \n",
    "        # This parameter affects the magnitude of the gradients of the solution.\n",
    "        # Increasing its value makes the training more difficult.\n",
    "        self.X = self.sample_data_domain(size)\n",
    "        self.Y = self.sample_data_boundary(size_each_bndry)\n",
    "        self.ref_u = self.ref_u_nn(u_coeff)\n",
    "        self.rng = np.random.default_rng()\n",
    "        self.X_batch = None\n",
    "        self.Y_batch = None\n",
    "        \n",
    "    # Reference solution\n",
    "    class ref_u_nn(nn.Module):\n",
    "        def __init__(self, coeff):\n",
    "            super(PoissonEqnByPINN.ref_u_nn, self).__init__()\n",
    "            self.coeff = coeff\n",
    "        def forward(self, x):\n",
    "            return (x[:,0]**2 + 1.0 * torch.sin(x[:,1] * self.coeff)).reshape((-1,1))      \n",
    "    \n",
    "    def create_model(self, layer_dims):\n",
    "        return create_sequential_nn(layer_dims)\n",
    "\n",
    "    def get_reference_solution(self):\n",
    "        return self.ref_u\n",
    "\n",
    "    def laplacian(self, model, x):\n",
    "        u = model(x)\n",
    "        u_x = torch.autograd.grad(\n",
    "                u.sum(), x,\n",
    "                retain_graph=True,\n",
    "                create_graph=True,\n",
    "                allow_unused=True\n",
    "            )[0]\n",
    "        u_xx = 0 \n",
    "        for i in range(2):\n",
    "            tmp = torch.autograd.grad(\n",
    "                     u_x[:,i].sum(), x,\n",
    "                     retain_graph=True,\n",
    "                     create_graph=True,\n",
    "                     allow_unused=True\n",
    "                 )[0]\n",
    "            if tmp is not None:\n",
    "                u_xx += tmp[:,i:i+1]\n",
    "        return u_xx\n",
    "    \n",
    "    def sample_X_batch(self, batch_size):\n",
    "        \n",
    "        batch_idx_X = self.rng.integers(self.X.shape[0], size=batch_size)\n",
    "        self.X_batch = torch.tensor(self.X[batch_idx_X, :], requires_grad=True).float()\n",
    "\n",
    "    def sample_Y_batch(self, batch_size):\n",
    "        \n",
    "        batch_idx_Y = self.rng.integers(self.Y.shape[0], size=batch_size)\n",
    "        self.Y_batch = torch.tensor(self.Y[batch_idx_Y, :]).float()  \n",
    "        \n",
    "    def sample_XY_batch(self, batch_size):\n",
    "        self.sample_X_batch(batch_size)\n",
    "        self.sample_Y_batch(batch_size)\n",
    "        \n",
    "    def get_X_batch(self):\n",
    "        return self.X_batch\n",
    "    \n",
    "    def get_Y_batch(self):\n",
    "        return self.Y_batch\n",
    "    \n",
    "    def f(self, x):   \n",
    "        return self.laplacian(self.ref_u, x).detach()    \n",
    "\n",
    "    def g(self, x):\n",
    "        return self.ref_u(x).detach()\n",
    "\n",
    "    def F(self, model):\n",
    "        u_xx = self.laplacian(model, self.X_batch)\n",
    "        return ((u_xx - self.f(self.X_batch))**2).mean().reshape((1))\n",
    "\n",
    "    def G(self, model):\n",
    "        u = model(self.Y_batch)\n",
    "        return ((u-self.g(self.Y_batch))**2).mean().reshape((1))\n",
    "    \n",
    "    def sample_data_domain(self, size):\n",
    "        return np.random.rand(size, 2) \n",
    "\n",
    "    def sample_data_boundary(self, size_each_bndry):\n",
    "        # left boundary\n",
    "        data_whole = np.column_stack([np.zeros(size_each_bndry), np.random.rand(size_each_bndry)]) \n",
    "        # right boundary\n",
    "        data = np.column_stack([np.ones(size_each_bndry), np.random.rand(size_each_bndry)]) \n",
    "        data_whole = np.concatenate([data_whole, data])\n",
    "        # top boundary\n",
    "        data = np.column_stack([np.random.rand(size_each_bndry),np.ones(size_each_bndry)]) \n",
    "        data_whole = np.concatenate([data_whole, data])   \n",
    "        # bottom boundary\n",
    "        data = np.column_stack([np.random.rand(size_each_bndry),np.zeros(size_each_bndry)])     \n",
    "        data_whole = np.concatenate([data_whole, data])\n",
    "\n",
    "        return data_whole    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac057844",
   "metadata": {},
   "source": [
    "### The third one is an eigenvalue PDE in $\\mathbb{R}^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "377f4934",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "class EigenPDE():\n",
    "    def __init__(self, pot_V, beta, num_eig_funcs=1, eig_w=[1.0], size=2000, size_each_bndry=1000):    \n",
    "        self.V = pot_V\n",
    "        self.beta = beta\n",
    "        self.rng = np.random.default_rng()\n",
    "        self.num_eig_funcs = num_eig_funcs\n",
    "        self.eig_w = eig_w\n",
    "        self.X = self.sample_data_domain(size)\n",
    "        self.Yb = self.sample_data_boundary(size_each_bndry)\n",
    "        self.Y = [self.X, self.Yb]\n",
    "        \n",
    "        self.X_batch=None\n",
    "        self.Yb_batch=None\n",
    "        \n",
    "        self._ij_list = list(itertools.combinations(range(self.num_eig_funcs), 2))\n",
    "        self._num_ij_pairs = len(self._ij_list)\n",
    "        \n",
    "    def create_model(self, layer_dims):\n",
    "        return nn.ModuleList([create_sequential_nn(layer_dims) for idx in range(self.num_eig_funcs)])\n",
    "    \n",
    "    def sample_X_batch(self, batch_size):\n",
    "        \n",
    "        batch_idx_X = self.rng.integers(self.X.shape[0], size=batch_size)\n",
    "        self.X_batch = torch.tensor(self.X[batch_idx_X, :], requires_grad=True).float()\n",
    "    \n",
    "    def sample_Y_batch(self, batch_size):\n",
    "        self.sample_X_batch(batch_size)\n",
    "        self.sample_Yb_batch(batch_size)\n",
    "        \n",
    "    def sample_Yb_batch(self, batch_size):\n",
    "        batch_idx_Yb = self.rng.integers(self.Yb.shape[0], size=batch_size)\n",
    "        self.Yb_batch = torch.tensor(self.Yb[batch_idx_Yb, :]).float()  \n",
    "    \n",
    "    def get_X_batch(self):\n",
    "        return self.X_batch\n",
    "    \n",
    "    def get_Y_batch(self):\n",
    "        return [self.X_batch, self.Yb_batch]\n",
    "    \n",
    "    def F(self, model):\n",
    "                    \n",
    "        X = self.X_batch\n",
    "        \n",
    "        y = [m(X) for m in model]\n",
    "\n",
    "        y_grad_vec = torch.stack([torch.autograd.grad(outputs=y[idx].sum(), \n",
    "                                                      inputs=X, retain_graph=True, \n",
    "                                                      create_graph=True)[0] \n",
    "                                  for idx in range(self.num_eig_funcs)], dim=2)\n",
    "        \n",
    "        # Mean and variance evaluated on data\n",
    "        mean_list = [y[idx].mean() for idx in range(self.num_eig_funcs)]\n",
    "        var_list = [(y[idx]**2).mean() - mean_list[idx]**2 for idx in range(self.num_eig_funcs)]\n",
    "\n",
    "        # Compute Rayleigh quotients as eigenvalues\n",
    "        eig_vals = torch.tensor([1.0 / self.beta * torch.mean((y_grad_vec[:,:,idx]**2).sum(dim=1)) \n",
    "                                 / var_list[idx] for idx in range(self.num_eig_funcs)])\n",
    "\n",
    "        cvec = np.argsort(eig_vals)\n",
    "        # Sort the eigenvalues \n",
    "        eig_vals = eig_vals[cvec]\n",
    "\n",
    "        non_penalty_loss = 1.0 / self.beta * sum([self.eig_w[idx] * torch.mean((y_grad_vec[:,:,cvec[idx]]**2).sum(dim=1)) \n",
    "                                                  / (var_list[cvec[idx]]) for idx in range(self.num_eig_funcs)])\n",
    "\n",
    "        return non_penalty_loss\n",
    "            \n",
    "    def G(self, model):\n",
    "        X = self.X_batch\n",
    "        y = [m(X) for m in model]\n",
    "        \n",
    "        penalty = torch.zeros(1, requires_grad=True)\n",
    "        \n",
    "        # Mean and variance evaluated on data\n",
    "        mean_list = [y[idx].mean() for idx in range(self.num_eig_funcs)]\n",
    "        var_list = [(y[idx]**2).mean() - mean_list[idx]**2 for idx in range(self.num_eig_funcs)]\n",
    "\n",
    "        # Sum of squares of variance for each eigenfunction\n",
    "        penalty = sum([(var_list[idx] - 1.0)**2 for idx in range(self.num_eig_funcs)])\n",
    "                \n",
    "        for idx in range(self._num_ij_pairs):\n",
    "            ij = self._ij_list[idx]\n",
    "            # Sum of squares of covariance between two different eigenfunctions\n",
    "            penalty += ((y[ij[0]] * y[ij[1]]).mean() - mean_list[ij[0]] * mean_list[ij[1]])**2\n",
    "\n",
    "        return penalty\n",
    "    \n",
    "    def sample_data_domain(self, size):\n",
    "        X_uniform = np.random.rand(size, 2) \n",
    "        weights = [math.exp(-self.beta * self.V(x)) for x in X_uniform]\n",
    "        return np.array(random.choices(X_uniform, weights, k=size))\n",
    "\n",
    "    def sample_data_boundary(self, size_each_bndry):\n",
    "        # left boundary\n",
    "        data_whole = np.column_stack([np.zeros(size_each_bndry), np.random.rand(size_each_bndry)]) \n",
    "        # right boundary\n",
    "        data = np.column_stack([np.ones(size_each_bndry), np.random.rand(size_each_bndry)]) \n",
    "        data_whole = np.concatenate([data_whole, data])\n",
    "        # top boundary\n",
    "        data = np.column_stack([np.random.rand(size_each_bndry),np.ones(size_each_bndry)]) \n",
    "        data_whole = np.concatenate([data_whole, data])   \n",
    "        # bottom boundary\n",
    "        data = np.column_stack([np.random.rand(size_each_bndry),np.zeros(size_each_bndry)])     \n",
    "        data_whole = np.concatenate([data_whole, data])\n",
    "\n",
    "        return data_whole    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f5130",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
